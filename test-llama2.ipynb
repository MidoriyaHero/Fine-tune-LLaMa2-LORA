{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c01481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:38:52.366970Z",
     "iopub.status.busy": "2023-12-21T05:38:52.366645Z",
     "iopub.status.idle": "2023-12-21T05:39:09.662447Z",
     "shell.execute_reply": "2023-12-21T05:39:09.661426Z"
    },
    "papermill": {
     "duration": 17.304156,
     "end_time": "2023-12-21T05:39:09.664958",
     "exception": false,
     "start_time": "2023-12-21T05:38:52.360802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q accelerate peft bitsandbytes transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959e0e90",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-21T05:39:09.673395Z",
     "iopub.status.busy": "2023-12-21T05:39:09.673086Z",
     "iopub.status.idle": "2023-12-21T05:39:29.658491Z",
     "shell.execute_reply": "2023-12-21T05:39:29.657572Z"
    },
    "papermill": {
     "duration": 19.992028,
     "end_time": "2023-12-21T05:39:29.660733",
     "exception": false,
     "start_time": "2023-12-21T05:39:09.668705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, torch, logging\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300282e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:39:29.669043Z",
     "iopub.status.busy": "2023-12-21T05:39:29.668731Z",
     "iopub.status.idle": "2023-12-21T05:39:31.028279Z",
     "shell.execute_reply": "2023-12-21T05:39:31.027273Z"
    },
    "papermill": {
     "duration": 1.366318,
     "end_time": "2023-12-21T05:39:31.030766",
     "exception": false,
     "start_time": "2023-12-21T05:39:29.664448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6959269d8b46eebc39dbc09466281f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5598ba730d5460a8bfcc4c8bbac2ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970c78c2d2604b2ba7c9da201785885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d05f5443f840eeb1b1dd93f1c9a571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b69d28c41948bea6d6d8904f0ff2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset\n",
    "#data_name = \"RafaelMPereira/HealthCareMagic-100k-Chat-Format-en\"\n",
    "#training_data = load_dataset(data_name, split=\"train\")\n",
    "\n",
    "# Model and tokenizer names\n",
    "base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "refined_model = \"/kaggle/input/llama2-1/llama-2-7b-mlabonne-enhanced\"\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  # Fix for fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3f7d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:39:31.041156Z",
     "iopub.status.busy": "2023-12-21T05:39:31.040808Z",
     "iopub.status.idle": "2023-12-21T05:41:44.207612Z",
     "shell.execute_reply": "2023-12-21T05:41:44.206708Z"
    },
    "papermill": {
     "duration": 133.268868,
     "end_time": "2023-12-21T05:41:44.304394",
     "exception": false,
     "start_time": "2023-12-21T05:39:31.035526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4179849914ab4cb2a7cd200e5b7a4bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87032490d17478694b0e2bffe166b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b488c560644548b745560f2bfbc864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3d3446c3c14a70b69d77a5ac1f6c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6364a1befb7c4cbe853b40a29f789b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb519305ad48472581f050f6c00d3868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc1969a0ec74305bad80eade8fa7134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:557: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n",
      "\n",
      "Thrown during validation:\n",
      "`do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/merged_model/tokenizer_config.json',\n",
       " '/kaggle/working/merged_model/special_tokens_map.json',\n",
       " '/kaggle/working/merged_model/tokenizer.model',\n",
       " '/kaggle/working/merged_model/added_tokens.json',\n",
       " '/kaggle/working/merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "base_model_name,\n",
    "return_dict=True,\n",
    "torch_dtype=torch.float16,\n",
    "device_map='auto',\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, refined_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "save_dir = \"/kaggle/working/merged_model\"\n",
    "model.save_pretrained(save_dir, safe_serialization=True)\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.save_pretrained(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25db0e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:41:44.352477Z",
     "iopub.status.busy": "2023-12-21T05:41:44.352103Z",
     "iopub.status.idle": "2023-12-21T05:41:45.372302Z",
     "shell.execute_reply": "2023-12-21T05:41:45.370939Z"
    },
    "papermill": {
     "duration": 1.030525,
     "end_time": "2023-12-21T05:41:45.374822",
     "exception": false,
     "start_time": "2023-12-21T05:41:44.344297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afd6dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:41:45.397301Z",
     "iopub.status.busy": "2023-12-21T05:41:45.396211Z",
     "iopub.status.idle": "2023-12-21T05:41:45.405399Z",
     "shell.execute_reply": "2023-12-21T05:41:45.404355Z"
    },
    "papermill": {
     "duration": 0.023337,
     "end_time": "2023-12-21T05:41:45.407508",
     "exception": false,
     "start_time": "2023-12-21T05:41:45.384171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/merged_model/config.json' target='_blank'>/kaggle/working/merged_model/config.json</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/merged_model/config.json"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'/kaggle/working/merged_model/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da53445e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:41:45.442079Z",
     "iopub.status.busy": "2023-12-21T05:41:45.441066Z",
     "iopub.status.idle": "2023-12-21T05:51:58.737469Z",
     "shell.execute_reply": "2023-12-21T05:51:58.734852Z"
    },
    "papermill": {
     "duration": 613.322746,
     "end_time": "2023-12-21T05:51:58.752484",
     "exception": false,
     "start_time": "2023-12-21T05:41:45.429738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c6f56f68ab4189927f1101b5dd0978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: I feel uncomfortable with my abdominal, and get headache, what should I do? <bot>: Hi, Thanks for posting your query.\n",
      "I have gone through your query and I understand your concerns. The symptoms you have mentioned are not specific to any particular disease. However, you should get a complete blood count, liver function test, thyroid function test and an ultrasound abdomen to rule out any underlying pathology. If the reports are normal, you can take a course of antibiotics and anti-inflammatory Chat Doctor.  If the symptoms persist, you should consult your doctor. I hope my answer helps. Please feel free to ask if you have any further queries. Wishing you good health, Chat Doctor. 30 minutes. Thank you. Take care.  Chat Doctor.  Internal Medicine.  Chat Doctor.  Specialist in Chronic Diseases.  Chat Doctor.  Specialist in Diabetes.  Chat Doctor.  Specialist in Cardiovascular Diseases.  Chat Doctor.  Specialist in Respiratory Diseases.  Chat Doctor.  Specialist in Cancer.  Chat Doctor.  Specialist in Rheumatology.  Chat Doctor.  Specialist in Neurology.  Chat Doctor.  Specialist in Psychiatry.  Chat Doctor.  Specialist in Nutrition.  Chat Doctor.  Specialist in Obesity.  Chat Doctor.  Specialist in Orthopedics.  Chat Doctor.  Specialist in Pediatrics.  Chat Doctor.  Specialist in Ophthalmology.  Chat Doctor.  Specialist in ENT.  Chat Doctor.  Specialist in Dermatology.  Chat Doctor.  Specialist in Urology.  Chat Doctor.  Specialist in Gastroenterology.  Chat Doctor.  Specialist in Anesthesia.  Chat Doctor.  Specialist in Pathology.  Chat Doctor.  Specialist in Radiology.  Chat Doctor.  Specialist in Immunology.  Chat Doctor.  Specialist in Hematology.  Chat Doctor.  Specialist in\n"
     ]
    }
   ],
   "source": [
    "# Generate Text\n",
    "query = \"I feel uncomfortable with my abdominal, and get headache, what should I do?\"\n",
    "refined_model = \"/kaggle/working/merged_model\"\n",
    "\n",
    "# Tokenizer\n",
    "base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  # Fix for fp16\n",
    "\n",
    "text_gen = pipeline(task=\"text-generation\", model=refined_model, tokenizer=llama_tokenizer, max_length=500)\n",
    "output = text_gen(f\"<human>: {query} <bot>:\")\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a17f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T05:51:58.767008Z",
     "iopub.status.busy": "2023-12-21T05:51:58.766695Z",
     "iopub.status.idle": "2023-12-21T06:01:08.632721Z",
     "shell.execute_reply": "2023-12-21T06:01:08.631746Z"
    },
    "papermill": {
     "duration": 549.882314,
     "end_time": "2023-12-21T06:01:08.640957",
     "exception": false,
     "start_time": "2023-12-21T05:51:58.758643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: I feel uncomfortable with my abdominal, and get headache, what should I do? <bot>: Hi, Thanks for posting your query.\n",
      "I have gone through your query and I understand your concerns. The symptoms you have mentioned are not specific to any particular disease. However, you should get a complete blood count, liver function test, thyroid function test and an ultrasound abdomen to rule out any underlying pathology. If the reports are normal, you can take a course of antibiotics and anti-inflammatory Chat Doctor.  If the symptoms persist, you should consult your doctor. I hope my answer helps. Please feel free to ask if you have any further queries. Wishing you good health, Chat Doctor. 30 minutes. Thank you. Take care.  Chat Doctor.  Internal Medicine.  Chat Doctor.  Specialist in Chronic Diseases.  Chat Doctor.  Specialist in Diabetes.  Chat Doctor.  Specialist in Cardiovascular Diseases.  Chat Doctor.  Specialist in Respiratory Diseases.  Chat Doctor.  Specialist in Cancer.  Chat Doctor.  Specialist in Rheumatology.  Chat Doctor.  Specialist in Neurology.  Chat Doctor.  Specialist in Psychiatry.  Chat Doctor.  Specialist in Nutrition.  Chat Doctor.  Specialist in Obesity.  Chat Doctor.  Specialist in Orthopedics.  Chat Doctor.  Specialist in Pediatrics.  Chat Doctor.  Specialist in Ophthalmology.  Chat Doctor.  Specialist in ENT.  Chat Doctor.  Specialist in Dermatology.  Chat Doctor.  Specialist in Urology.  Chat Doctor.  Specialist in Gastroenterology.  Chat Doctor.  Specialist in Anesthesia.  Chat Doctor.  Specialist in Pathology.  Chat Doctor.  Specialist in Radiology.  Chat Doctor.  Specialist in Immunology.  Chat Doctor.  Specialist in Hematology.  Chat Doctor.  Specialist in\n"
     ]
    }
   ],
   "source": [
    "query = \"I feel uncomfortable with my abdominal, and get headache, what should I do?\"\n",
    "output = text_gen(f\"<human>: {query} <bot>:\")\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5f26f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T06:01:08.654371Z",
     "iopub.status.busy": "2023-12-21T06:01:08.654059Z"
    },
    "papermill": {
     "duration": 8.724913,
     "end_time": "2023-12-21T06:01:17.372064",
     "exception": false,
     "start_time": "2023-12-21T06:01:08.647151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ee6bf9d9d74babbe582027353ac416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate\n",
    "from transformers import LlamaForCausalLM\n",
    "refined_model = \"/kaggle/working/merged_model\"\n",
    "text_gen = LlamaForCausalLM.from_pretrained(\n",
    "    refined_model,\n",
    "    #local_files_only=True\n",
    ")\n",
    "\n",
    "query = \"I feel uncomfortable with my abdominal, and get headache, what should I do?\"\n",
    "input = llama_tokenizer(f\"<human>: {query} <bot>:\")\n",
    "output = text_gen(**input)\n",
    "print(output[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4201766,
     "sourceId": 7251948,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1349.340377,
   "end_time": "2023-12-21T06:01:18.393447",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-21T05:38:49.053070",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
